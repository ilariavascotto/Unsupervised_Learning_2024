{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 2: Principal Component Analysis\n",
    "You can use external libraries for linear algebra operations but you are expected to write your own algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "Use the  ```Dry_Bean_Dataset.xlsx``` available on the  ```github``` page of the labs.\n",
    "- Divide your dataset into a train and a test set.\n",
    "- Preprocess the data by centering the variables and dividing them by their standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../Datasets/Dry_Bean_Dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Class']\n",
    "X = df.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "y=np.array(y)\n",
    "encoder.fit(y.reshape(-1,1))\n",
    "y = encoder.transform(y.reshape(-1, 1))\n",
    "print(y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = Xtrain.mean()\n",
    "X_std = Xtrain.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = (Xtrain-X_mean )/X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write your own algorithm to perform PCA on the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the intent of these laboratories is for YOU to learn and test the algorithms, we will not provide a \"hand-made\" version of the algorithm in these solutions (as your code will be commented during the exam).\n",
    "#We will use instead the sklearn version of PCA. You can check if your results match the provided solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA() #this will keep all the components\n",
    "#alternatively you can specify the number of components you want to keep by writing \n",
    "# pca = PCA(n_components =3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(Xtrain) #this is just a fit of the model to the training set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the training set, obtain and plot the eigenvalue spectrum using the log-scale for the y-axis. What number of principal components would you select?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(pca.singular_values_, \"o-\")\n",
    "plt.title(\"Eigenvalues spectrum\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(np.log(pca.singular_values_),\"o-\")\n",
    "plt.title(\"Log-scale for eigenvalues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(pca.explained_variance_ratio_,\"o-\")\n",
    "plt.title(\"Amount of variance explained by each PC\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Project the data (training set) in the first two principal components and color by class. Do it also for three principal components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = pca.transform(Xtrain)\n",
    "print(X_new.shape)\n",
    "\n",
    "#you can also fit the model and apply the dimensionality reduction to the same set by writing\n",
    "#pca.fit_transform(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_3 = X_new[:,:3] #we need at most 3 PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = np.array(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.column_stack((X_new_3, ytrain))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(data[:,0], data[:,1], c=data[:,3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "axes = plt.axes(projection='3d')\n",
    "axes.scatter3D(data[:,0], data[:,1], data[:,2], c=data[:,3])\n",
    "axes.view_init(30,15)\n",
    "axes.set_xlabel('1st PC')\n",
    "axes.set_ylabel('2nd PC')\n",
    "axes.set_zlabel('3rd PC')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For an increasing number of principal components (1 to 16):\n",
    "- - Apply a multinomial logistic regression to learn a model on the training set (use  ```sklearn.linear_model.LogisticRegression``` ).\n",
    "- - Transform the test set with the matrix learned from the traning set. Make a prediction with the logistic model learned. \n",
    "- - Assess the quality of the predictions and comment on the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = (Xtest- Xtest.mean())/Xtest.std() #proprocessing of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "for i in range(X_new.shape[1]): #X_new is the PCA transformation of the test set with all components kepts\n",
    "    lr = LogisticRegression(multi_class='multinomial', max_iter=1000)\n",
    "    lr.fit(X_new[:,:i+1], ytrain.ravel())\n",
    "\n",
    "    x_PC = pca.transform(Xtest)\n",
    "    x_PC = x_PC[:,:i+1] #keep only the needed PCs\n",
    "    \n",
    "    yhat = lr.predict(x_PC)\n",
    "    print(i, \": \", lr.score(x_PC, ytest.ravel()))\n",
    "    score.append(lr.score(x_PC, ytest.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(score, \"o-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The maximum values of the accuracy score is reached with {np.argmax(score)} PCs and it is equal to {np.max(score)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "Try to apply PCA to the Swiss Roll dataset ($n=1000$) from Lab 1 and plot the projection on the first two principal components. Choose an appropriate color scheme for visualization and comment on your results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swiss_roll(n): #from lab 1\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    n: int\n",
    "        Number of points to generate\"\"\"\n",
    "    \n",
    "    data = np.zeros((n,3))\n",
    "    phi = np.random.uniform(low=1.5*np.pi, high=4.5*np.pi, size=n)\n",
    "    psi = np.random.uniform(0,10,n)\n",
    "               \n",
    "    data[:,0]=phi*np.cos(phi) #x coordinte\n",
    "    data[:,1]=phi*np.sin(phi) #y coordinate\n",
    "    data[:,2]=psi #z coordinate\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = swiss_roll(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = (X-np.mean(X)) #or \n",
    "X = (X-np.mean(X))/np.std(X) #but it is only necessary to centralize the data in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.title(\"Swiss roll\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_swiss = PCA(n_components=2)\n",
    "X_transformed = pca_swiss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(X_transformed[:,0], X_transformed[:,1])\n",
    "plt.title(\"Swiss roll - 2 PCs\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ul2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
