{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 5: Recap on Dimensionality Reduction Techniques\n",
    "You are required to use your implementations from previous labs, but for the new algorithms introduced today you can use external libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import struct\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "Download the ```fashion mnist``` dataset available at the following [link](https://github.com/zalandoresearch/fashion-mnist#get-the-data).\n",
    "\n",
    "**Today we are going to see how to program an autoencoder, next time (November 10th) we will see the solutions to the whole exercise.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_idx(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = read_idx('../Datasets/fashion_mnist//train-images-idx3-ubyte.gz')\n",
    "ytrain=read_idx('../Datasets/fashion_mnist/train-labels-idx1-ubyte.gz')\n",
    "\n",
    "Xtest = read_idx('../Datasets/fashion_mnist//t10k-images-idx3-ubyte.gz')\n",
    "ytest =read_idx('../Datasets/fashion_mnist/t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(Xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = { 0: 'T-shirt/top',\n",
    "                1: 'Trouser',\n",
    "                2: 'Pullover', \n",
    "                3: 'Dress', \n",
    "                4: 'Coat', \n",
    "                5: 'Sandal', \n",
    "                6: 'Shirt', \n",
    "                7: 'Sneaker',\n",
    "                8: 'Bag', \n",
    "                9: 'Ankle boot' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Xtrain[0] #first image in the dataset\n",
    "label = ytrain[0]\n",
    "\n",
    "print(f\"Class: {label} ({labels_dict[label]})\")\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_row = 4\n",
    "n_col = 5\n",
    "\n",
    "n = n_row * n_col\n",
    "#Let's have a look at the first 20 images in the dataset\n",
    "images = Xtrain[:n]\n",
    "lab = ytrain[:n]\n",
    "\n",
    "fig, ax = plt.subplots(n_row, n_col, figsize = (1.5*n_col, 2*n_row))\n",
    "for i in range(n):\n",
    "    ax_ = ax[i//n_col, i%n_col]\n",
    "    ax_.imshow(images[i], cmap='gray')\n",
    "    ax_.set_title(labels_dict[lab[i]])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize it so that the values are in the [0,1] range\n",
    "Xtrain = Xtrain/255\n",
    "Xtest = Xtest/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = Xtrain - Xtrain.mean(axis=0)\n",
    "Xtest = Xtest - Xtest.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the images\n",
    "# this is the format in which you need your data for today\n",
    "\n",
    "Xtrain = Xtrain.reshape((Xtrain.shape[0],Xtrain.shape[1]*Xtrain.shape[2]))\n",
    "Xtest = Xtest.reshape((Xtest.shape[0], Xtest.shape[1]*Xtest.shape[2]))\n",
    "\n",
    "print(Xtrain.shape)\n",
    "print(Xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder\n",
    "The above preprocessing steps are required for all the algorithms you will be working with during this lab.\n",
    "\n",
    "The following applies only to the autoencoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shaping necessary for the autoencoder\n",
    "\n",
    "X_train = Xtrain.reshape((Xtrain.shape[0], 1, 28, 28))\n",
    "X_test = Xtest.reshape((Xtest.shape[0], 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_test = torch.from_numpy(X_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torch.utils.data.TensorDataset(X_train, X_train)\n",
    "train_set, val_set = torch.utils.data.random_split(train_set, [round(len(train_set)*0.8), round(len(train_set)*0.2)])\n",
    "test_set = torch.utils.data.TensorDataset(X_test, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle = True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=128, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image('Autoencoder/autoencoder-architecture.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model class\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        # define the encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=784, out_features=1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 250),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(250, 125),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(125, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2)  \n",
    "        )\n",
    "        # the output of the encoder is the projection in the bottleneck (in this case, a 2-dimensional space)\n",
    "\n",
    "        # define the decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 125),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(125, 250),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(250, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 784),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        # the output of the decoder is the reconstructed image which was passed as input\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded= self.encoder(x.flatten(1)) \n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded.view(-1,1,28,28), encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, loss_func, optimizer, num_epochs= 50):\n",
    "    l_train =[]\n",
    "    l_val = []\n",
    "\n",
    "    for epoch in range(num_epochs): \n",
    "        model.train()\n",
    "        loss_tr=[]\n",
    "\n",
    "        for it, (images_raw, images_out) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()           \n",
    "            y, _ = model(images_raw)\n",
    "            loss = loss_func(images_out, y)\n",
    "            loss_tr.append(loss.cpu().data.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "       \n",
    "       #Evaluation\n",
    "        model.eval()\n",
    "        loss_ts = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for it, (images_raw, images_out) in enumerate(val_loader):\n",
    "                y, _ = model(images_raw)\n",
    "                loss = loss_func(images_out, y)\n",
    "                loss_ts.append(loss.detach().cpu().numpy())\n",
    "\n",
    "        print(f\"Epoch {epoch}, training_loss: {np.mean(loss_tr)} , validation_loss {np.mean(loss_ts)}\")\n",
    "\n",
    "        l_train.append(np.mean(loss_tr))\n",
    "        l_val.append(np.mean(loss_ts))\n",
    "    \n",
    "    return l_train, l_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.RAdam(model.parameters(), lr = 0.001)\n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_PRETRAINED_MODEL=True\n",
    "\n",
    "if USE_PRETRAINED_MODEL:\n",
    "    model.load_state_dict(torch.load(f'Autoencoder/autoencoder_26_10_2023.pt'))\n",
    "    print(\"Model loaded\")\n",
    "\n",
    "    display(Image('Autoencoder/Loss_autoencoder.png')) #this is the loss I have saved during the training of the autoencoder\n",
    "    \n",
    "else:\n",
    "   l_train , l_val = train(model, train_loader, val_loader, loss_func, optimizer,  num_epochs=50) \n",
    "   #with 50 epochs it takes around 10 minutes (on the whole dataset) on my PC\n",
    "   torch.save(model.state_dict(), 'Autoencoder/autoencoder.pt')\n",
    "   print(\"Model saved\")\n",
    "\n",
    "   plt.plot(l_train, label=\"Train\")\n",
    "   plt.plot(l_val, label=\"Validation\")\n",
    "   plt.legend()\n",
    "   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, encoded = model(test_set.tensors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.detach().numpy()\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=0\n",
    "\n",
    "image = Xtest[idx].reshape((28,28))\n",
    "image_out = out[idx].reshape((28,28))\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "ax[0].imshow(image, cmap='gray')\n",
    "ax[1].imshow(image_out, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = encoded.detach().numpy()\n",
    "print(encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "cmap = plt.get_cmap('jet', 10)\n",
    "p = plt.scatter(encoded[:,0], encoded[:,1], c=ytest, cmap=cmap)\n",
    "cb = plt.colorbar(p)\n",
    "cb.ax.set_title('Class', fontsize=11)\n",
    "cb.ax.set_yticks(ticks=(np.arange(10)))\n",
    "cb.ax.set_yticklabels(labels_dict.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on the whole trainset\n",
    "_, encoded = model(train_set.dataset.tensors[0])\n",
    "encoded = encoded.detach().numpy()\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "cmap = plt.get_cmap('jet', 10)\n",
    "p = plt.scatter(encoded[:,0], encoded[:,1], c=ytrain, cmap=cmap)\n",
    "cb = plt.colorbar(p)\n",
    "cb.ax.set_title('Class', fontsize=11)\n",
    "cb.ax.set_yticks(ticks=(np.arange(10)))\n",
    "cb.ax.set_yticklabels(labels_dict.values())\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are interested in Variational Autoencoders, there is a lot of documentation (and examples) online. I suggest you use the ```pytorch``` framework other than ```tensorflow``` or ```keras```. \n",
    "\n",
    "Since most of you have not followed a course on Deep Learning yet, we refrain from the examples with VAE but be aware of their existance and usefulness.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dott",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
